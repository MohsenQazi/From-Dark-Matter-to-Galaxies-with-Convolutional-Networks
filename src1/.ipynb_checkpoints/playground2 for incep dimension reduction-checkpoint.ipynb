{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import argparse\n",
    "\n",
    "from train_f import *\n",
    "from Dataset import Dataset\n",
    "from Models import *\n",
    "from args import args\n",
    "import os\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#args\n",
    "mini = 0\n",
    "medium = 0\n",
    "medium1 = 0\n",
    "lr = 0.001\n",
    "model_idx = 2\n",
    "epochs = 1\n",
    "batch_size = 20\n",
    "loss_weight = 80\n",
    "weight_decay = 0.0\n",
    "print_freq = 400\n",
    "target_cat = 'count'\n",
    "target_class = 0\n",
    "plot_label = ''\n",
    "load_model = 0\n",
    "save_name = ''\n",
    "conv1_out, conv3_out, conv5_out = 6,8,10\n",
    "record_results = 0\n",
    "#yfloss_weight = torch.Tensor([1]).to(device)\n",
    "vel = 0\n",
    "normalize = 0\n",
    "C_model = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4370753f3641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mBEST_ACC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mEPSILON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrained'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrained'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# the following four variables are global variables that record the statistics \n",
    "# for each epoch so that the plot can be produced\n",
    "TRAIN_LOSS,VAL_LOSS, VAL_ACC, VAL_RECALL, VAL_PRECISION = [],[],[],[],[]\n",
    "BEST_VAL_LOSS = 999999999\n",
    "BEST_RECALL = 0\n",
    "BEST_PRECISION = 0\n",
    "BEST_F1SCORE = 0\n",
    "BEST_ACC = 0\n",
    "EPSILON = 1e-5\n",
    "if not os.path.exists('pretrained'):\n",
    "    os.makedirs('pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initial_loss(train_loader, val_loader, model, criterion, target_class):\n",
    "    #AverageMeter is a object that record the sum, avg, count and val of the target stats\n",
    "    train_losses = AverageMeter()\n",
    "    val_losses = AverageMeter()  \n",
    "    correct = 0\n",
    "    # ptotal = 0  #count of all positive predictions\n",
    "    # tp = 0    #true positive\n",
    "    total = 0 #total count of data\n",
    "    TPRs = AverageMeter()\n",
    "    FPRs = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            # add a dimension, from (1, 32, 32, 32) to (1,1,32,32,32)\n",
    "            input = input.to(device).float()\n",
    "            if target_class == 0:\n",
    "                target = target.to(device).long()\n",
    "            elif target_class == 1:\n",
    "                target = target.to(device).float()\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            # print(\"target1: \", target.size())\n",
    "            # print(\"output: \", output.size())\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            train_losses.update(loss.item(), input.size(0))\n",
    "\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            # add a dimension, from (1, 32, 32, 32) to (1,1,32,32,32)\n",
    "\n",
    "            input = input.to(device).float()\n",
    "            if target_class == 0:\n",
    "                target = target.to(device).long()\n",
    "            elif target_class == 1:\n",
    "                target = target.to(device).float()\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            val_losses.update(loss.item(), input.size(0))\n",
    "            if target_class == 0:\n",
    "                outputs = F.softmax(output, dim=1)\n",
    "                predicted = outputs.max(1)[1]\n",
    "                total += np.prod(target.shape)\n",
    "                correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
    "                #ptotal += (target.view_as(predicted) >= 1).sum().item()\n",
    "                #tp += torch.mul(predicted.eq(target.view_as(predicted)),(target.view_as(predicted)>= 1)).sum().item()\n",
    "                TPR, gp, FPR, gf = confusion_matrix_calc(predicted,target)\n",
    "                TPRs.update(TPR,gp)\n",
    "                FPRs.update(FPR,gf)            \n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            val_losses.update(loss.item(), input.size(0))  \n",
    "\n",
    "    # recall =  tp/ptotal*100  #recall = true positive / count of all positive predictions  \n",
    "    if target_class == 0:\n",
    "        acc = correct/total*100\n",
    "        recall = TPRs.avg * 100\n",
    "        precision = TPRs.sum/(TPRs.sum + FPRs.sum + EPSILON) * 100  \n",
    "        VAL_RECALL.append(recall)\n",
    "        VAL_ACC.append(acc)\n",
    "        VAL_PRECISION.append(precision)  \n",
    "\n",
    "    TRAIN_LOSS.append(train_losses.avg)\n",
    "    VAL_LOSS.append(val_losses.avg)\n",
    "    if target_class == 0:\n",
    "        print('Epoch Train Loss {train_losses.avg:.4f}, Test Loss {val_losses.avg:.4f},\\\n",
    "         Test Accuracy {acc:.4f},  Test Recall {recall:.4f}\\t Precision {precision:.4f}\\t'.format(train_losses = train_losses, \\\n",
    "            val_losses=val_losses,acc=acc, recall = recall, precision = precision))\n",
    "    else:\n",
    "        print('Epoch Train Loss {train_losses.avg:.4f}, Test Loss {val_losses.avg:.4f}'\\\n",
    "            .format(train_losses = train_losses, val_losses=val_losses))\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq, target_class):\n",
    "\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # add a dimension, from (1, 32, 32, 32) to (1,1,32,32,32)\n",
    "        input = input.to(device).float()\n",
    "        if target_class == 0:\n",
    "            target = target.to(device).long()\n",
    "        elif target_class == 1:\n",
    "            target = target.to(device).float()\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        #print(torch.nonzero(target).size())\n",
    "        loss = criterion(output, target)\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "    TRAIN_LOSS.append(losses.avg)\n",
    "    print('Epoch {0} : Train: Loss {loss.avg:.4f}\\t'.format(epoch, loss=losses))\n",
    "    \n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, target_class, save_name):\n",
    "    global BEST_VAL_LOSS\n",
    "    global BEST_RECALL\n",
    "    global BEST_PRECISION\n",
    "    global BEST_F1SCORE\n",
    "    global BEST_ACC\n",
    "    batch_time = AverageMeter()\n",
    "    val_losses = AverageMeter()\n",
    "    TPRs = AverageMeter()\n",
    "    FPRs = AverageMeter()  \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.to(device).float()\n",
    "            if target_class == 0:\n",
    "                target = target.to(device).long()\n",
    "            elif target_class == 1:\n",
    "                target = target.to(device).float()\n",
    "            \n",
    "            \n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            if target_class == 0:\n",
    "                outputs = F.softmax(output, dim=1)\n",
    "                predicted = outputs.max(1)[1]\n",
    "                total += np.prod(target.shape)\n",
    "                correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
    "                TPR, gp, FPR, gf = confusion_matrix_calc(predicted,target)\n",
    "                TPRs.update(TPR,gp)\n",
    "                FPRs.update(FPR,gf)\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            val_losses.update(loss.item(), input.size(0))\n",
    "\n",
    "    \n",
    "    if target_class == 0:\n",
    "        recall = TPRs.avg * 100\n",
    "        precision = TPRs.sum/(TPRs.sum + FPRs.sum + EPSILON) * 100\n",
    "        F1score = 2*((precision*recall)/(precision+recall+ EPSILON))\n",
    "        acc = correct/total*100\n",
    "        VAL_RECALL.append(recall)\n",
    "        VAL_ACC.append(acc)\n",
    "        VAL_PRECISION.append(precision)\n",
    "        if val_losses.avg < BEST_VAL_LOSS:\n",
    "            BEST_RECALL = recall\n",
    "            BEST_PRECISION = precision\n",
    "            BEST_F1SCORE = F1score\n",
    "            BEST_ACC = acc\n",
    "    \n",
    "    if val_losses.avg < BEST_VAL_LOSS:\n",
    "        if len(save_name) > 0:\n",
    "            #torch.save(model, 'pretrained/' + str(save_name) + '.pt')\n",
    "            torch.save(model.state_dict(), 'pretrained/' + str(save_name) + '.pth')\n",
    "        BEST_VAL_LOSS = val_losses.avg\n",
    "    VAL_LOSS.append(val_losses.avg)\n",
    "    if target_class == 0:\n",
    "        print('Epoch {0} :Test Loss {val_losses.avg:.4f},\\\n",
    "         Test Accuracy {acc:.4f},  Test Recall {recall:.4f}\\t Precision {precision:.4f} F1 score  {F1score:.4f}\\t'.format(epoch, \\\n",
    "            val_losses=val_losses,acc=acc, recall = recall, precision = precision, F1score = F1score))\n",
    "    else:\n",
    "        print('Epoch {0} : Test Loss {val_losses.avg:.4f}'\\\n",
    "            .format(epoch, val_losses=val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#index for the cube, each tuple corresponds to a cude\n",
    "#test data\n",
    "if mini:\n",
    "    train_data = [(832, 640, 224),(864, 640, 224)]\n",
    "    val_data = [(832, 640, 224),(864, 640, 224)]\n",
    "    test_data = [(832, 640, 224),(864, 640, 224)]\n",
    "else:\n",
    "    if medium1:\n",
    "        data_range = 130\n",
    "        random_idx = 1\n",
    "    elif medium:\n",
    "        data_range = 512\n",
    "        random_idx = 1\n",
    "    else:\n",
    "        data_range = 1024\n",
    "        random_idx = 0\n",
    "\n",
    "    pos=list(np.arange(0,data_range,32))\n",
    "    ranges=list(product(pos,repeat=3))\n",
    "    random.seed(7)\n",
    "    if random_idx == 1:\n",
    "        random.shuffle(ranges)\n",
    "        train_data = ranges[:int(np.round(len(ranges)*0.6))]\n",
    "        val_data=ranges[int(np.round(len(ranges)*0.6)):int(np.round(len(ranges)*0.8))]\n",
    "        test_data = ranges[int(np.round(len(ranges)*0.8)):]\n",
    "    else:\n",
    "        train_data, val_data, test_data = [],[],[]\n",
    "\n",
    "        for i in range(0,data_range,32):\n",
    "            for j in range(0,data_range,32):\n",
    "                for k in range(0,data_range,32):\n",
    "                    idx = (i,j,k)\n",
    "                    if i <=416 and j<= 416:\n",
    "                        val_data.append(idx)\n",
    "                    elif i>=484 and j>= 448 and k>= 448:\n",
    "                        test_data.append(idx)\n",
    "                    else:\n",
    "                        train_data.append(idx)\n",
    "# #build dataloader\n",
    "params = {'batch_size': batch_size,\n",
    "      'shuffle': True,\n",
    "      'num_workers':20}\n",
    "\n",
    "training_set, validation_set = Dataset(train_data,cat = target_cat,reg = target_class, vel = vel), Dataset(val_data, cat = target_cat,reg = target_class, vel = vel, normalize = normalize)\n",
    "testing_set= Dataset(test_data, cat= target_cat, reg = target_class, vel = vel, normalize = normalize)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "testing_generator = data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicConv3d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, bias=False, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "\n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, conv1_out, conv3_out, conv5_out):\n",
    "        super(InceptionE, self).__init__()\n",
    "        self.pool_out = 3\n",
    "        self.conv1_out = conv1_out\n",
    "        self.conv3_out = conv3_out\n",
    "        self.conv5_out = conv5_out\n",
    "        self.branch1x1 = BasicConv3d(in_channels, self.conv1_out, kernel_size=1)\n",
    "\n",
    "        self.branch3x3 = BasicConv3d(in_channels, self.conv3_out, kernel_size=3, padding = 1)\n",
    "        \n",
    "\n",
    "        self.branch5x5 = BasicConv3d(in_channels, self.conv5_out, kernel_size=5, padding = 2)\n",
    "        self.branch_pool = BasicConv3d(in_channels, self.pool_out, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5(x)\n",
    "        \n",
    "        branch_pool = F.avg_pool3d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, channels, conv1_out, conv3_out, conv5_out, reg = 0):\n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1_out = conv1_out\n",
    "        self.conv3_out = conv3_out\n",
    "        self.conv5_out = conv5_out\n",
    "        self.incep = InceptionE(channels, conv1_out = conv1_out, conv3_out = conv3_out, conv5_out = conv5_out)\n",
    "        conv_in = conv1_out + conv3_out + conv5_out + 3\n",
    "        self.conv1 = BasicConv3d(conv_in, conv_in, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = BasicConv3d(conv_in, conv_in//2, kernel_size = 3, padding = 1)\n",
    "        self.reg = reg\n",
    "        if self.reg:\n",
    "            dim_out = 1\n",
    "        else:\n",
    "            dim_out = 2\n",
    "        self.conv3 = BasicConv3d(conv_in//2, dim_out, kernel_size = 1)\n",
    "    def forward(self, x):\n",
    "        b_size = x.size(0)\n",
    "        incep1 = self.incep(x)\n",
    "        #print('incep1 = ', incep1.size())\n",
    "        conv1=self.conv1(incep1)\n",
    "        conv2=self.conv2(conv1) \n",
    "        conv3=self.conv3(conv2)\n",
    "        if self.reg:\n",
    "            conv3 = conv3.squeeze(1)\n",
    "        return conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# #set up device\n",
    "\n",
    "# #build model\n",
    "dim_out = 1\n",
    "if vel == 1:\n",
    "    dim_in = 4\n",
    "else:\n",
    "    dim_in = 1\n",
    "    dim = 1 ## need to be changed later\n",
    "if model_idx == 0:\n",
    "    model = SimpleUnet(dim, target_class).to(device)\n",
    "elif model_idx == 1:\n",
    "    model = Baseline(dim, dim).to(device)\n",
    "elif model_idx == 2:\n",
    "    model = Inception(dim_in, conv1_out, conv3_out, conv5_out).to(device)\n",
    "elif model_idx == 3:\n",
    "    model = R2Unet(dim_in, dim_out, t = 3, reg = target_class).to(device)\n",
    "elif model_idx == 4:\n",
    "    mask_model = one_layer_conv(dim,one_layer_outchannel = 8,kernel_size = 3,non_linearity = 'ReLU6', transformation = 'sqrt_root'\n",
    "                                , power = 0.25).to(device)\n",
    "    #state_dict = torch.load('../trained_model/epoch_10_MSE.pth')\n",
    "    state_dict = torch.load('./pretrained/' + C_model + '.pth')\n",
    "    mask_model.load_state_dict('state_dict')\n",
    "    pred_model = R2Unet(dim,dim,t=3,reg = target_class).to(device)\n",
    "    model = two_phase_conv(mask_model,pred_model,thres = thres)\n",
    "elif model_idx == 5:\n",
    "    mask_model = R2Unet(dim_in, dim_out, t = 3).to(device)\n",
    "    state_dict = torch.load('./pretrained/' + C_model + '.pth')\n",
    "    mask_model.load_state_dict(state_dict)\n",
    "    pred_model = R2Unet(dim_in,dim_out,t=3,reg = target_class).to(device)\n",
    "    model = two_phase_conv(mask_model,pred_model)\n",
    "elif model_idx == 6:\n",
    "    model = R2Unet_atten(dim, dim, t = 3, reg = 0).to(device)\n",
    "\n",
    "elif model_idx == 7:\n",
    "    mask_model = Inception(dim_in, conv1_out, conv3_out, conv5_out).to(device)\n",
    "    state_dict = torch.load('./pretrained/' + C_model + '.pth')\n",
    "\n",
    "    mask_model.load_state_dict(state_dict)\n",
    "    pred_model = R2Unet(dim_in,dim_out,t=3,reg = target_class).to(device)\n",
    "    model = two_phase_conv(mask_model,pred_model)\n",
    "elif model_idx == 8:\n",
    "    model = Inception(dim, conv1_out, conv3_out, conv5_out, reg = target_class).to(device)\n",
    "else:\n",
    "    print('model not exist')\n",
    "\n",
    "if load_model:\n",
    "    model = torch.load('pretrained/mytraining.pt')\n",
    "#criterion = nn.MSELoss().to(device) #yueqiu\n",
    "#weight = torch.Tensor([0.99,0.05,0.05])\n",
    "if target_class == 0:\n",
    "    criterion = nn.CrossEntropyLoss(weight = get_loss_weight(loss_weight, num_class = 2)).to(device)\n",
    "    print('criterion classification')\n",
    "    #criterion = yfloss(weight = get_loss_weight(loss_weight, num_class = 2).to(device), w = yfloss_weight, device = device)\n",
    "else:\n",
    "    criterion = weighted_nn_loss(loss_weight)\n",
    "    #criterion = nn.MSELoss() #yueqiu\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=weight_decay)\n",
    "initial_loss(training_generator, validation_generator, model, criterion, target_class)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    adjust_learning_rate(lr, optimizer, epoch)\n",
    "    train(training_generator, model, criterion, optimizer, epoch, print_freq, target_class = target_class)\n",
    "    #evaluate on validation set\n",
    "    validate(validation_generator, model, criterion, epoch, target_class = target_class, save_name = save_name)\n",
    "if len(plot_label) == 0:\n",
    "    plot_label = '_' + str(target_class) + '_' + str(model_idx) + '_'\n",
    "train_plot(TRAIN_LOSS,VAL_LOSS, VAL_ACC, VAL_RECALL, VAL_PRECISION, target_class, plot_label = plot_label)\n",
    "if target_class == 0:\n",
    "    if record_results:\n",
    "        args = parse_args()\n",
    "        f= open(\"all_results\",\"a+\")\n",
    "        f.write(\"arguments: %s\" %(args) + '\\n')\n",
    "        f.write('Test Loss {BEST_VAL_LOSS:.5f},  Test Accuracy {BEST_ACC:.4f},  Test Recall {BEST_RECALL:.4f},  \\\n",
    "        Precision {BEST_PRECISION:.4f}   F1 score  {BEST_F1SCORE:.4f}\\n'.format( \\\n",
    "                    BEST_VAL_LOSS=BEST_VAL_LOSS,BEST_ACC=BEST_ACC, BEST_RECALL = BEST_RECALL, BEST_PRECISION = BEST_PRECISION, BEST_F1SCORE =  BEST_F1SCORE))\n",
    "        f.close() \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
