{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.models as models\n",
    "\n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from args import args\n",
    "from train_f import *\n",
    "from Dataset import Dataset\n",
    "#from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        \n",
    "        super(Baseline, self).__init__()\n",
    "        '''\n",
    "        torch.nn.Conv3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout) \n",
    "        torch.nn.AvgPool3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout)     \n",
    "        '''\n",
    "        '''\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size)\n",
    "        nn.AvgPool3d()\n",
    "        '''\n",
    "        self.draft_model = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, cube):\n",
    "        cube = self.draft_model(cube)\n",
    "        return cube\n",
    "    \n",
    "class SimpleUnet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        \n",
    "        super(SimpleUnet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.Simple_Unet = nn.Sequential(\n",
    "            self.conv_layer(self.in_channels, 16),\n",
    "            self.conv_layer(16, 16),\n",
    "            nn.AvgPool3d(2),\n",
    "            self.conv_layer(16,32),\n",
    "            nn.AvgPool3d(2),\n",
    "            self.conv_layer(32,64),\n",
    "            self.up_conv_layer(64, 64, 3),\n",
    "            self.conv_layer(64, 32),\n",
    "            self.up_conv_layer(32, 32, 3),\n",
    "            self.conv_layer(32, 16),\n",
    "            self.up_conv_layer(16, 16, 2),\n",
    "            self.conv_layer(16, 8),\n",
    "            self.up_conv_layer(8, 8, 2),\n",
    "            self.conv_layer(8, 4),\n",
    "            self.conv_layer(4, 1)\n",
    "        )\n",
    "    \n",
    "    def conv_layer(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=True):\n",
    "        layers = nn.Sequential(\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "        nn.BatchNorm3d(out_channels),\n",
    "        nn.LeakyReLU())\n",
    "        return layers\n",
    "    \n",
    "    def up_conv_layer(self, in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, bias=True):\n",
    "        layers = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            # should be feat_in*2 or feat_in\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.LeakyReLU())\n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    def forward(self, cube):\n",
    "        cube = self.Simple_Unet(cube)\n",
    "        return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "\n",
    "        # add a dimension, from (1, 32, 32, 32) to (1,1,32,32,32)\n",
    "        input = input.unsqueeze(dim = 1).to(device).float()\n",
    "        target = target.unsqueeze(dim = 1).to(device).float()\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.train()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.unsqueeze(dim = 1).to(device).float()\n",
    "            target = target.unsqueeze(dim = 1).to(device).float()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "        print('Test: Time {batch_time.val:.3f} \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(batch_time=batch_time, loss=losses))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index for the cube, each tuple corresponds to a cude\n",
    "train_data = [(800, 640, 224)]\n",
    "val_data = [(800, 640, 224)]\n",
    "test_data = [(800, 640, 224)]\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 50,\n",
    "          'shuffle': False,\n",
    "          #'shuffle': True,\n",
    "          'num_workers':20}\n",
    "max_epochs = 100\n",
    "\n",
    "training_set, validation_set = Dataset(train_data), Dataset(val_data)\n",
    "testing_set= Dataset(test_data)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "testing_generator = data.DataLoader(testing_set, **params)\n",
    "\n",
    "for i, (dark,full) in enumerate(testing_generator):\n",
    "    dark=dark\n",
    "    full=full\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1\n",
    "model = SimpleUnet(dim).to(device)\n",
    "criterion = nn.MSELoss().to(device) #yueqiu\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Time 0.379 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys3202/.conda/envs/dark/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Time 0.427 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.400 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.396 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.429 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.412 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.407 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.372 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.427 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n",
      "Test: Time 0.402 \t\t\t\t\t\t\t\t\t\tLoss 0.5122 (0.5122)\t\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "#     if args.distributed:\n",
    "#         train_sampler.set_epoch(epoch)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    #train(training_generator, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    validate(validation_generator, model, criterion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
