{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.models as models\n",
    "\n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from torch.autograd import Variable\n",
    "#from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay = 1e-4\n",
    "    start_epoch = 0\n",
    "    epochs = 10\n",
    "    gpu = None\n",
    "    print_freq = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, lists):\n",
    "        'Initialization'\n",
    "        self.IDs = lists\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.IDs[index]\n",
    "        d_box=np.load('/scratch/xz2139/cosmo_dark/arrays/'+str(ID[0])+'_'+str(ID[1])+'_'+str(ID[2])+'.npy')\n",
    "        f_box=np.load('/scratch/xz2139/cosmo_full/arrays/'+str(ID[0])+'_'+str(ID[1])+'_'+str(ID[2])+'.npy')\n",
    "        return d_box,f_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        \n",
    "        super(Baseline, self).__init__()\n",
    "        '''\n",
    "        torch.nn.Conv3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout) \n",
    "        torch.nn.AvgPool3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout)     \n",
    "        '''\n",
    "        '''\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size)\n",
    "        nn.AvgPool3d()\n",
    "        '''\n",
    "        self.draft_model = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, cube):\n",
    "        cube = self.draft_model(cube)\n",
    "        return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = [(800, 640, 224)]\n",
    "val_data = [(800, 640, 224)]\n",
    "test_data = [(800, 640, 224)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            input = input.cuda(args.gpu, non_blocking=True)\n",
    "        #target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        input = input.unsqueeze(dim = 1)\n",
    "        target = target.unsqueeze(dim = 1)\n",
    "        output = model(input.float())\n",
    "        \n",
    "        loss = criterion(output, target.float())\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        #top1.update(prec1[0], input.size(0))\n",
    "        #top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                input = input.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec1[0], input.size(0))\n",
    "            top5.update(prec5[0], input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                       i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       top1=top1, top5=top5))\n",
    "\n",
    "        print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 3,\n",
    "          'shuffle': False,\n",
    "          #'shuffle': True,\n",
    "          'num_workers':20}\n",
    "max_epochs = 100\n",
    "\n",
    "training_set, validation_set = Dataset(train_data), Dataset(val_data)\n",
    "testing_set= Dataset(test_data)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "testing_generator = data.DataLoader(testing_set, **params)\n",
    "\n",
    "for i, (dark,full) in enumerate(testing_generator):\n",
    "    dark=dark\n",
    "    full=full\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_prec1 = 0\n",
    "dim = 1\n",
    "model = Baseline(dim, dim)\n",
    "criterion = nn.MSELoss().cuda() #yueqiu\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime 0.122 (0.122)\tData 0.109 (0.109)\tLoss 0.1144 (0.1144)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [1][0/1]\tTime 0.085 (0.085)\tData 0.073 (0.073)\tLoss 0.0115 (0.0115)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [2][0/1]\tTime 0.083 (0.083)\tData 0.071 (0.071)\tLoss 0.0048 (0.0048)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [3][0/1]\tTime 0.082 (0.082)\tData 0.071 (0.071)\tLoss 0.0041 (0.0041)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [4][0/1]\tTime 0.082 (0.082)\tData 0.071 (0.071)\tLoss 0.0040 (0.0040)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [5][0/1]\tTime 0.081 (0.081)\tData 0.070 (0.070)\tLoss 0.0040 (0.0040)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [6][0/1]\tTime 0.081 (0.081)\tData 0.070 (0.070)\tLoss 0.0040 (0.0040)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [7][0/1]\tTime 0.081 (0.081)\tData 0.071 (0.071)\tLoss 0.0040 (0.0040)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [8][0/1]\tTime 0.081 (0.081)\tData 0.070 (0.070)\tLoss 0.0040 (0.0040)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [9][0/1]\tTime 0.082 (0.082)\tData 0.071 (0.071)\tLoss 0.0040 (0.0040)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "#     if args.distributed:\n",
    "#         train_sampler.set_epoch(epoch)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(training_generator, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "#     prec1 = validate(validation_generator, model, criterion)\n",
    "\n",
    "#     # remember best prec@1 and save checkpoint\n",
    "#     is_best = prec1 > best_prec1\n",
    "#     best_prec1 = max(prec1, best_prec1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
